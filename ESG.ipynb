{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hindupathy1980/ESG-BERT/blob/main/ESG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "riieA2uAgY84",
        "outputId": "566df94b-c9a0-4847-9a88-141ef7c1a12c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_tags=[\"Business_Ethics\",\n",
        "\"Data_Security\",\n",
        "\"Access_And_Affordability\",\n",
        "\"Business_Model_Resilience\",\n",
        "\"Competitive_Behavior\",\n",
        "\"Critical_Incident_Risk_Management\",\n",
        "\"Customer_Welfare\",\n",
        "\"Director_Removal\",\n",
        "\"Employee_Engagement_Inclusion_And_Diversity\",\n",
        "\"Employee_Health_And_Safety\",\n",
        "\"Human_Rights_And_Community_Relations\",\n",
        "\"Labor_Practices\",\n",
        "\"Management_Of_Legal_And_Regulatory_Framework\",\n",
        "\"Physical_Impacts_Of_Climate_Change\",\n",
        "\"Product_Quality_And_Safety\",\n",
        "\"Product_Design_And_Lifecycle_Management\",\n",
        "\"Selling_Practices_And_Product_Labeling\",\n",
        "\"Supply_Chain_Management\",\n",
        "\"Systemic_Risk_Management\",\n",
        "\"Waste_And_Hazardous_Materials_Management\",\n",
        "\"Water_And_Wastewater_Management\",\n",
        "\"Air_Quality\",\n",
        "\"Customer_Privacy\",\n",
        "\"Ecological_Impacts\",\n",
        "\"Energy_Management\",\n",
        "\"GHG_Emissions\",\"Water_stress\",\"Toxic_Emissions\",\"Bribe\"]\n",
        "print(label_tags)"
      ],
      "metadata": {
        "id": "WSEHpboghhky",
        "outputId": "a2c11627-3e56-41b1-dc04-715d7e816add",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Business_Ethics', 'Data_Security', 'Access_And_Affordability', 'Business_Model_Resilience', 'Competitive_Behavior', 'Critical_Incident_Risk_Management', 'Customer_Welfare', 'Director_Removal', 'Employee_Engagement_Inclusion_And_Diversity', 'Employee_Health_And_Safety', 'Human_Rights_And_Community_Relations', 'Labor_Practices', 'Management_Of_Legal_And_Regulatory_Framework', 'Physical_Impacts_Of_Climate_Change', 'Product_Quality_And_Safety', 'Product_Design_And_Lifecycle_Management', 'Selling_Practices_And_Product_Labeling', 'Supply_Chain_Management', 'Systemic_Risk_Management', 'Waste_And_Hazardous_Materials_Management', 'Water_And_Wastewater_Management', 'Air_Quality', 'Customer_Privacy', 'Ecological_Impacts', 'Energy_Management', 'GHG_Emissions', 'Water_stress', 'Toxic_Emissions', 'Bribe']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install torchserve torch-model-archiver\n",
        "!pip install torchvision \n"
      ],
      "metadata": {
        "id": "31MGQ4lumyCb",
        "outputId": "4d94f4eb-3a0f-442b-c8a1-165883dca60d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.24.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.5 MB 6.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n",
            "\u001b[K     |████████████████████████████████| 163 kB 63.3 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 62.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.10.1 tokenizers-0.13.1 transformers-4.24.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchserve\n",
            "  Downloading torchserve-0.6.0-1-py2.py3-none-any.whl (19.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.6 MB 1.3 MB/s \n",
            "\u001b[?25hCollecting torch-model-archiver\n",
            "  Downloading torch_model_archiver-0.6.0-py2.py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from torchserve) (5.4.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchserve) (21.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from torchserve) (7.1.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from torchserve) (0.37.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torchserve) (0.16.0)\n",
            "Collecting enum-compat\n",
            "  Downloading enum_compat-0.0.3-py3-none-any.whl (1.3 kB)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torchserve) (3.0.9)\n",
            "Installing collected packages: enum-compat, torchserve, torch-model-archiver\n",
            "Successfully installed enum-compat-0.0.3 torch-model-archiver-0.6.0 torchserve-0.6.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.13.1+cu113)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.21.6)\n",
            "Requirement already satisfied: torch==1.12.1 in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torchvision) (4.1.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision) (2.23.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (1.24.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from transformers import BertForSequenceClassification\n",
        "import torch\n",
        "model1 = BertForSequenceClassification.from_pretrained(\n",
        "    './drive/MyDrive/ESG-BERT', \n",
        "    #labels=label_tags,\n",
        "    num_labels = 29, #number of classifications\n",
        "   output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        "    ignore_mismatched_sizes=True\n",
        ")\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model1.to(device)\n"
      ],
      "metadata": {
        "id": "3_FISNgfidRD",
        "outputId": "39049ee4-19d8-4598-afdc-bdc7a2e8f069",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ./drive/MyDrive/ESG-BERT and are newly initialized because the shapes did not match:\n",
            "- classifier.weight: found shape torch.Size([26, 768]) in the checkpoint and torch.Size([29, 768]) in the model instantiated\n",
            "- classifier.bias: found shape torch.Size([26]) in the checkpoint and torch.Size([29]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=29, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!torch-model-archiver --model-name \"bert\" --version 1.0 --serialized-file \"./drive/MyDrive/ESG-BERT/pytorch_model.bin\" --extra-files \"./drive/MyDrive/ESG-BERT/config.json,./drive/MyDrive/ESG-BERT/vocab.txt\" --handler \"./drive/MyDrive/ESG-BERT/handler.py\""
      ],
      "metadata": {
        "id": "1U_wlD7MvDgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cp  ./drive/MyDrive/ESG-BERT/bert.mar ./drive/MyDrive/ESG-BERT/model_store\n"
      ],
      "metadata": {
        "id": "5pbnNM9oPAAb"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification\n",
        "import torch\n",
        "model2 = BertForSequenceClassification.from_pretrained(\n",
        "    './drive/MyDrive/ESG-BERT', \n",
        "    #labels=label_tags,\n",
        "    num_labels = 29, #number of classifications\n",
        "   output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        "    ignore_mismatched_sizes=True\n",
        ")\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model2.to(device)"
      ],
      "metadata": {
        "id": "wkRAxVISqasJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab847ae5-fc08-407d-d74f-98fb3574d72f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ./drive/MyDrive/ESG-BERT and are newly initialized because the shapes did not match:\n",
            "- classifier.weight: found shape torch.Size([26, 768]) in the checkpoint and torch.Size([29, 768]) in the model instantiated\n",
            "- classifier.bias: found shape torch.Size([26]) in the checkpoint and torch.Size([29]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=29, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer\n",
        "from transformers import Trainer, TrainingArguments\n",
        "cvec = CountVectorizer()\n",
        "import pandas as pd\n",
        "text=[\"U.S. detects first case of COVID-19 variant as Biden offers gloomy vaccine outlook Shortly after his remarks, Colorado's Governor Jared Polis announced on Twitter that his state had discovered a case of a highly infectious coronavirus variant B.1.1.7 first detected in the United Kingdom.WILMINGTON, Del./WASHINGTON, Dec 29 (Reuters) — The first known U.S. case of a highly infectious coronavirus variant was detected in Colorado on Tuesday, and President-elect Joe Biden said that it could take years for most Americans to be vaccinated for the virus at current distribution rates.Biden's prediction of a grim winter appeared aimed at lowering public expectations that the pandemic will be over soon after he takes office on Jan. 20, while also sending a message to Congress that his new administration wants to significantly increase spending to expedite vaccine distribution, expand testing and provide funding to states to help reopen schools.Biden, a Democrat, said some 2 million people have been vaccinated, well short of the 20 million that outgoing Republican President Donald Trump had promised by the end of the year. Biden defeated Trump in a November election.As I long feared and warned, the effort to distribute and administer the vaccine is not progressing as it should, the Democrat added. At the current rate, it's going to take years, not months, to vaccinate the American people, Biden said in Wilmington, Delaware.RELATED: Kamala Harris receives COVID-19 shot in bid to boost U.S. vaccine confidence Sen. Harris, who is Black and Asian-American, will become the second high-profile person from an ethnic minority background to receive the vaccine after Surgeon General Jerome Adams on Dec. 18.McConnell puts off vote on $2,000 aid checks, urges Senate override Trump defense veto While McConnell blocked immediate consideration of a measure to increase COVID-19 relief payments to $2,000, he suggested the Senate would at least examine the issue along with two others Trump has raised — limits on big technology companies and the integrity of elections.\"]\n",
        "df=pd.DataFrame(text,columns=[\"message\"])\n",
        "new_x = df.message\n",
        "from transformers import BertForSequenceClassification\n",
        "import torch\n",
        "model2 = BertForSequenceClassification.from_pretrained(\n",
        "    './drive/MyDrive/ESG-BERT', \n",
        "    #labels=label_tags,\n",
        "    num_labels = 29, #number of classifications\n",
        "   output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        "    ignore_mismatched_sizes=True\n",
        ")\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # output directory\n",
        "    num_train_epochs=3,              # total # of training epochs\n",
        "    per_device_train_batch_size=16,  # batch size per device during training\n",
        "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
        "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    logging_dir='./logs',            # directory for storing logs\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model2,                         # the instantiated 🤗 Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=test_dataset            # evaluation dataset\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "id": "z4XwY59HtfNz",
        "outputId": "1899115b-68d5-438c-9a60-d405ccba39bd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ./drive/MyDrive/ESG-BERT and are newly initialized because the shapes did not match:\n",
            "- classifier.weight: found shape torch.Size([26, 768]) in the checkpoint and torch.Size([29, 768]) in the model instantiated\n",
            "- classifier.bias: found shape torch.Size([26]) in the checkpoint and torch.Size([29]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-800043d244c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m,\u001b[0m                         \u001b[0;31m# the instantiated 🤗 Transformers model to be trained\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_args\u001b[0m\u001b[0;34m,\u001b[0m                  \u001b[0;31m# training arguments, defined above\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m         \u001b[0;31m# training dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0meval_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_dataset\u001b[0m            \u001b[0;31m# evaluation dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m )\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_dataset' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!torchserve --stop \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8DMZV9xPQ68",
        "outputId": "ef798038-a2b1-48b2-e41d-abe5ff076ca6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TorchServe is not currently running.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!torchserve --start --model-store ./drive/MyDrive/ESG-BERT --models bert=bert.mar  --ts-config ./drive/MyDrive/ESG-BERT/config.properties\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bqKfCEMPyWu",
        "outputId": "b2efe616-586b-40cf-ae91-a8a5d9b93dfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing orphan pid file.\n",
            "WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.\n",
            "2022-11-02T18:43:54,259 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...\n",
            "2022-11-02T18:43:54,380 [INFO ] main org.pytorch.serve.ModelServer - \n",
            "Torchserve version: 0.6.0\n",
            "TS Home: /usr/local/lib/python3.7/dist-packages\n",
            "Current directory: /content\n",
            "Temp directory: /tmp\n",
            "Number of GPUs: 0\n",
            "Number of CPUs: 2\n",
            "Max heap size: 3248 M\n",
            "Python executable: /usr/bin/python3\n",
            "Config file: ./drive/MyDrive/ESG-BERT/config.properties\n",
            "Inference address: http://127.0.0.1:8443\n",
            "Management address: http://127.0.0.1:8444\n",
            "Metrics address: http://127.0.0.1:8445\n",
            "Model Store: /content/drive/MyDrive/ESG-BERT\n",
            "Initial Models: bert=bert.mar\n",
            "Log dir: /content/logs\n",
            "Metrics dir: /content/logs\n",
            "Netty threads: 0\n",
            "Netty client threads: 0\n",
            "Default workers per model: 2\n",
            "Blacklist Regex: N/A\n",
            "Maximum Response Size: 6553500\n",
            "Maximum Request Size: 6553500\n",
            "Limit Maximum Image Pixels: true\n",
            "Prefer direct buffer: false\n",
            "Allowed Urls: [file://.*|http(s)?://.*]\n",
            "Custom python dependency for model allowed: false\n",
            "Metrics report format: prometheus\n",
            "Enable metrics API: true\n",
            "Workflow Store: /content/drive/MyDrive/ESG-BERT\n",
            "Model config: N/A\n",
            "2022-11-02T18:43:54,392 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...\n",
            "2022-11-02T18:43:54,429 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: bert.mar\n",
            "2022-11-02T18:44:03,737 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model bert\n",
            "2022-11-02T18:44:03,739 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model bert\n",
            "2022-11-02T18:44:03,740 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model bert loaded.\n",
            "2022-11-02T18:44:03,741 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: bert, count: 2\n",
            "2022-11-02T18:44:03,766 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.\n",
            "2022-11-02T18:44:03,769 [DEBUG] W-9000-bert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3, /usr/local/lib/python3.7/dist-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000]\n",
            "2022-11-02T18:44:03,776 [DEBUG] W-9001-bert_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3, /usr/local/lib/python3.7/dist-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001]\n",
            "2022-11-02T18:44:04,040 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8443\n",
            "2022-11-02T18:44:04,042 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.\n",
            "2022-11-02T18:44:04,058 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8444\n",
            "2022-11-02T18:44:04,059 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.\n",
            "2022-11-02T18:44:04,064 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8445\n",
            "Model server started.\n",
            "2022-11-02T18:44:04,949 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.\n",
            "2022-11-02T18:44:05,111 [ERROR] Thread-1 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):\n",
            "  File \"ts/metrics/metric_collector.py\", line 11, in <module>\n",
            "    from ts.metrics import system_metrics\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ts/__init__.py\", line 10, in <module>\n",
            "    from . import version\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ts/version.py\", line 7, in <module>\n",
            "    version_path = os.path.join(Path(__file__).resolve().parent, 'version.txt')\n",
            "  File \"/usr/lib/python3.7/posixpath.py\", line 80, in join\n",
            "    a = os.fspath(a)\n",
            "TypeError: expected str, bytes or os.PathLike object, not PosixPath\n",
            "\n",
            "2022-11-02T18:44:05,924 [INFO ] W-9000-bert_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000\n",
            "2022-11-02T18:44:05,928 [INFO ] W-9000-bert_1.0-stdout MODEL_LOG - [PID]549\n",
            "2022-11-02T18:44:05,929 [INFO ] W-9000-bert_1.0-stdout MODEL_LOG - Torch worker started.\n",
            "2022-11-02T18:44:05,930 [DEBUG] W-9000-bert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bert_1.0 State change null -> WORKER_STARTED\n",
            "2022-11-02T18:44:05,933 [INFO ] W-9000-bert_1.0-stdout MODEL_LOG - Python runtime: 3.7.15\n",
            "2022-11-02T18:44:05,940 [INFO ] W-9000-bert_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000\n",
            "2022-11-02T18:44:05,955 [INFO ] W-9000-bert_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.\n",
            "2022-11-02T18:44:05,963 [INFO ] W-9000-bert_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1667414645963\n",
            "2022-11-02T18:44:06,032 [INFO ] W-9001-bert_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001\n",
            "2022-11-02T18:44:06,034 [INFO ] W-9001-bert_1.0-stdout MODEL_LOG - [PID]548\n",
            "2022-11-02T18:44:06,035 [INFO ] W-9001-bert_1.0-stdout MODEL_LOG - Torch worker started.\n",
            "2022-11-02T18:44:06,035 [INFO ] W-9001-bert_1.0-stdout MODEL_LOG - Python runtime: 3.7.15\n",
            "2022-11-02T18:44:06,035 [DEBUG] W-9001-bert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-bert_1.0 State change null -> WORKER_STARTED\n",
            "2022-11-02T18:44:06,036 [INFO ] W-9001-bert_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001\n",
            "2022-11-02T18:44:06,041 [INFO ] W-9001-bert_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.\n",
            "2022-11-02T18:44:06,042 [INFO ] W-9001-bert_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1667414646042\n",
            "2022-11-02T18:44:06,091 [INFO ] W-9000-bert_1.0-stdout MODEL_LOG - model_name: bert, batchSize: 1\n",
            "2022-11-02T18:44:06,155 [INFO ] W-9001-bert_1.0-stdout MODEL_LOG - model_name: bert, batchSize: 1\n",
            "2022-11-02T18:44:11,070 [INFO ] W-9001-bert_1.0-stdout MODEL_LOG - NumExpr defaulting to 2 threads.\n",
            "2022-11-02T18:44:11,478 [INFO ] W-9000-bert_1.0-stdout MODEL_LOG - NumExpr defaulting to 2 threads.\n",
            "2022-11-02T18:44:18,641 [INFO ] W-9000-bert_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.\n",
            "2022-11-02T18:44:18,656 [INFO ] W-9000-bert_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 12556\n",
            "2022-11-02T18:44:18,657 [DEBUG] W-9000-bert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-bert_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED\n",
            "2022-11-02T18:44:18,657 [INFO ] W-9000-bert_1.0 TS_METRICS - W-9000-bert_1.0.ms:14903|#Level:Host|#hostname:8372a15ef036,timestamp:1667414658\n",
            "2022-11-02T18:44:18,658 [INFO ] W-9000-bert_1.0 TS_METRICS - WorkerThreadTime.ms:139|#Level:Host|#hostname:8372a15ef036,timestamp:1667414658\n",
            "2022-11-02T18:44:18,700 [INFO ] W-9001-bert_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.\n",
            "2022-11-02T18:44:18,701 [INFO ] W-9001-bert_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 12547\n",
            "2022-11-02T18:44:18,702 [DEBUG] W-9001-bert_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-bert_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED\n",
            "2022-11-02T18:44:18,702 [INFO ] W-9001-bert_1.0 TS_METRICS - W-9001-bert_1.0.ms:14945|#Level:Host|#hostname:8372a15ef036,timestamp:1667414658\n",
            "2022-11-02T18:44:18,703 [INFO ] W-9001-bert_1.0 TS_METRICS - WorkerThreadTime.ms:114|#Level:Host|#hostname:8372a15ef036,timestamp:1667414658\n",
            "2022-11-02T18:45:05,017 [ERROR] Thread-2 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):\n",
            "  File \"ts/metrics/metric_collector.py\", line 11, in <module>\n",
            "    from ts.metrics import system_metrics\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ts/__init__.py\", line 10, in <module>\n",
            "    from . import version\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ts/version.py\", line 7, in <module>\n",
            "    version_path = os.path.join(Path(__file__).resolve().parent, 'version.txt')\n",
            "  File \"/usr/lib/python3.7/posixpath.py\", line 80, in join\n",
            "    a = os.fspath(a)\n",
            "TypeError: expected str, bytes or os.PathLike object, not PosixPath\n",
            "\n",
            "2022-11-02T18:46:04,990 [ERROR] Thread-3 org.pytorch.serve.metrics.MetricCollector - Traceback (most recent call last):\n",
            "  File \"ts/metrics/metric_collector.py\", line 11, in <module>\n",
            "    from ts.metrics import system_metrics\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ts/__init__.py\", line 10, in <module>\n",
            "    from . import version\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ts/version.py\", line 7, in <module>\n",
            "    version_path = os.path.join(Path(__file__).resolve().parent, 'version.txt')\n",
            "  File \"/usr/lib/python3.7/posixpath.py\", line 80, in join\n",
            "    a = os.fspath(a)\n",
            "TypeError: expected str, bytes or os.PathLike object, not PosixPath\n",
            "\n",
            "2022-11-02T18:46:42,351 [WARN ] W-9000-bert_1.0-stderr MODEL_LOG - Traceback (most recent call last):\n",
            "2022-11-02T18:46:42,353 [WARN ] W-9000-bert_1.0-stderr MODEL_LOG -   File \"/usr/local/lib/python3.7/dist-packages/ts/model_service_worker.py\", line 210, in <module>\n",
            "2022-11-02T18:46:42,357 [WARN ] W-9001-bert_1.0-stderr MODEL_LOG - Traceback (most recent call last):\n",
            "2022-11-02T18:46:42,360 [WARN ] W-9001-bert_1.0-stderr MODEL_LOG -   File \"/usr/local/lib/python3.7/dist-packages/ts/model_service_worker.py\", line 210, in <module>\n",
            "2022-11-02T18:46:42,361 [WARN ] W-9001-bert_1.0-stderr MODEL_LOG -     worker.run_server()\n",
            "2022-11-02T18:46:42,361 [WARN ] W-9000-bert_1.0-stderr MODEL_LOG -     worker.run_server()\n",
            "2022-11-02T18:46:42,364 [WARN ] W-9000-bert_1.0-stderr MODEL_LOG -   File \"/usr/local/lib/python3.7/dist-packages/ts/model_service_worker.py\", line 181, in run_server\n",
            "2022-11-02T18:46:42,363 [WARN ] W-9001-bert_1.0-stderr MODEL_LOG -   File \"/usr/local/lib/python3.7/dist-packages/ts/model_service_worker.py\", line 181, in run_server\n",
            "2022-11-02T18:46:42,366 [WARN ] W-9001-bert_1.0-stderr MODEL_LOG -     self.handle_connection(cl_socket)\n",
            "2022-11-02T18:46:42,366 [WARN ] W-9000-bert_1.0-stderr MODEL_LOG -     self.handle_connection(cl_socket)\n",
            "2022-11-02T18:46:42,373 [WARN ] W-9000-bert_1.0-stderr MODEL_LOG -   File \"/usr/local/lib/python3.7/dist-packages/ts/model_service_worker.py\", line 132, in handle_connection\n",
            "2022-11-02T18:46:42,378 [WARN ] W-9001-bert_1.0-stderr MODEL_LOG -   File \"/usr/local/lib/python3.7/dist-packages/ts/model_service_worker.py\", line 132, in handle_connection\n",
            "2022-11-02T18:46:42,382 [WARN ] W-9001-bert_1.0-stderr MODEL_LOG -     cmd, msg = retrieve_msg(cl_socket)\n",
            "2022-11-02T18:46:42,383 [WARN ] W-9000-bert_1.0-stderr MODEL_LOG -     cmd, msg = retrieve_msg(cl_socket)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -X post http://127.0.0.1:8443/predictions/bert -T ./drive/MyDrive/ESG-BERT/predict.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egmbpChLWKkn",
        "outputId": "da98742c-2adb-4924-d4cd-33697551b829"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "curl: (7) Failed to connect to 127.0.0.1 port 8443: Connection refused\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}